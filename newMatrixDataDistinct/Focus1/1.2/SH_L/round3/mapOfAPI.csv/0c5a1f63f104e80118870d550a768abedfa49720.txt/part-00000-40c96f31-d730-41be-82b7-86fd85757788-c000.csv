0	java/lang/Object/Object()
1	parquet/schema/PrimitiveType/getPrimitiveTypeName()
2	parquet/hadoop/metadata/ParquetMetadata/getBlocks()
3	java/io/BufferedReader/close()
4	parquet/hadoop/ParquetFileWriter/end(java.util.Map)
5	parquet/schema/MessageType/MessageType(java.lang.String,parquet.schema.Type[])
6	java/io/BufferedReader/BufferedReader(java.io.Reader)
7	java/util/List/get(int)
8	java/io/File/File(java.lang.String,java.lang.String)
9	java/util/Arrays/asList(T[])
10	parquet/hadoop/ParquetFileReader/ParquetFileReader(parquet.hadoop.api.Configuration,parquet.hadoop.Path,java.util.List,java.util.List)
11	java/util/HashMap/HashMap()
12	parquet/hadoop/ParquetFileReader/readNextRowGroup()
13	parquet/bytes/BytesInput/from(byte[])
14	parquet/hadoop/example/TestInputOutputFormat/waitForJob(parquet.hadoop.Job)
15	parquet/schema/GroupType/GroupType(parquet.schema.Type.Repetition,java.lang.String,parquet.schema.Type[])
16	parquet/hadoop/ParquetFileWriter/startBlock(long)
17	java/io/File/getAbsoluteFile()
18	java/lang/String/substring(int)
19	parquet/schema/MessageType/getColumnDescription(java.lang.String[])
20	parquet/column/page/PageReadStore/getRowCount()
21	parquet/hadoop/ParquetFileWriter/endColumn()
22	java/io/BufferedReader/readLine()
23	parquet/schema/Types/Builder/named(java.lang.String)
24	parquet/schema/MessageType/getMaxDefinitionLevel(java.lang.String[])
25	java/io/PrintStream/println(java.lang.String)
26	parquet/schema/MessageType/getType(java.lang.String[])
27	parquet/hadoop/PrintFooter/main(java.lang.String[])
28	parquet/hadoop/ParquetFileReader/readFooter(parquet.hadoop.api.Configuration,parquet.hadoop.Path)
29	parquet/hadoop/ParquetFileWriter/startColumn(parquet.column.ColumnDescriptor,long,parquet.hadoop.metadata.CompressionCodecName)
30	parquet/schema/MessageType/getMaxRepetitionLevel(java.lang.String[])
31	parquet/schema/PrimitiveType/PrimitiveType(parquet.schema.Type.Repetition,parquet.schema.PrimitiveType.PrimitiveTypeName,java.lang.String)
32	parquet/hadoop/ParquetOutputFormat/setCompression(parquet.hadoop.Job,parquet.hadoop.metadata.CompressionCodecName)
33	parquet/schema/Type/asPrimitiveType()
34	parquet/hadoop/ParquetFileWriter/writeDataPage(int,int,parquet.bytes.BytesInput,parquet.column.Encoding)
35	parquet/hadoop/example/ExampleOutputFormat/setSchema(parquet.hadoop.Job,parquet.schema.MessageType)
36	java/io/File/toURI()
37	java/lang/String/indexOf(java.lang.String)
38	java/io/File/delete()
39	parquet/schema/Type/toString()
40	parquet/hadoop/ParquetFileWriter/start()
41	parquet/hadoop/TestParquetFileWriter/validateContains(parquet.schema.MessageType,parquet.column.page.PageReadStore,java.lang.String[],int,parquet.bytes.BytesInput)
42	parquet/schema/MessageTypeParser/parseMessageType(java.lang.String)
43	java/io/FileReader/FileReader(java.io.File)
44	parquet/schema/Types/PrimitiveBuilder/length(int)
45	parquet/hadoop/ParquetFileWriter/endBlock()
46	parquet/hadoop/ParquetFileWriter/ParquetFileWriter(parquet.hadoop.api.Configuration,parquet.schema.MessageType,parquet.hadoop.Path)
47	java/io/File/File(java.lang.String)
48	java/util/List/size()
