0	java/lang/String/split(java.lang.String)
1	org/apache/spark/sql/execution/datasources/jdbc/JdbcUtils$/getSchemaOption(java.sql.Connection,org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions)
2	org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$4()
3	org/apache/spark/sql/execution/datasources/parquet/ParquetWriteSupport$$anonfun$org$apache$spark$sql$execution$datasources$parquet$ParquetWriteSupport$$makeWriter$5/5(org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport)
4	org/apache/spark/sql/catalyst/catalog/SessionCatalog/getTableMetadata(org.apache.spark.sql.catalyst.TableIdentifier)
5	scala/collection/Seq/apply(int)
6	scala/MatchError/MatchError(java.lang.Object)
7	scala/collection/Seq$/empty()
8	org/apache/spark/sql/execution/SparkSqlAstBuilder$$anonfun$visitManageResource$1/apply()
9	scala/Some/Some(java.lang.Object)
10	org/apache/spark/sql/catalyst/catalog/CatalogTable/withNewStorage$default$2()
11	org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/copy(scala.Option,scala.Option,scala.Option,scala.Option,boolean,scala.collection.immutable.Map)
12	org/apache/spark/sql/catalyst/catalog/CatalogTable/withNewStorage$default$3()
13	org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$5()
14	org/apache/spark/sql/catalyst/catalog/CatalogTable/withNewStorage(scala.Option,scala.Option,scala.Option,boolean,scala.Option,scala.collection.immutable.Map)
15	org/apache/spark/sql/internal/SQLConf/caseSensitiveAnalysis()
16	org/apache/spark/sql/execution/datasources/parquet/ParquetWriteSupport$$anonfun$org$apache$spark$sql$execution$datasources$parquet$ParquetWriteSupport$$makeWriter$12/12(org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport,scala.Function2[],org.apache.spark.sql.types.StructType)
17	org/apache/spark/sql/execution/datasources/jdbc/JdbcUtils$/saveTable(org.apache.spark.sql.Dataset,scala.Option,boolean,org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions)
18	org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterPartitions(org.apache.spark.sql.catalyst.TableIdentifier,scala.collection.Seq)
19	org/apache/spark/sql/catalyst/catalog/CatalogTable/withNewStorage$default$4()
20	org/apache/spark/sql/execution/datasources/parquet/ParquetWriteSupport$$anonfun$org$apache$spark$sql$execution$datasources$parquet$ParquetWriteSupport$$makeWriter$4/4(org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport)
21	org/apache/spark/sql/catalyst/expressions/AttributeSet/contains(org.apache.spark.sql.catalyst.expressions.NamedExpression)
22	java/sql/Connection/close()
23	org/apache/spark/sql/catalyst/catalog/CatalogTable/withNewStorage$default$5()
24	org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/storage()
25	scala/reflect/ClassTag$/apply(java.lang.Class)
26	scala/collection/mutable/StringBuilder/toString()
27	scala/Function0/apply()
28	org/apache/spark/sql/catalyst/catalog/SessionCatalog/getPartition(org.apache.spark.sql.catalyst.TableIdentifier,scala.collection.immutable.Map)
29	org/apache/spark/sql/catalyst/parser/ParserUtils$/remainder(org.antlr.v4.runtime.ParserRuleContext)
30	org/apache/spark/sql/execution/command/ListFilesCommand$/apply$default$1()
31	org/apache/spark/sql/execution/datasources/jdbc/JdbcUtils$/truncateTable(java.sql.Connection,java.lang.String)
32	org/apache/spark/sql/execution/datasources/parquet/ParquetWriteSupport$$anonfun$2/2(org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport)
33	scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
34	org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/copy$default$2()
35	org/apache/spark/sql/types/DecimalType$Fixed$/unapply(org.apache.spark.sql.types.DecimalType)
36	org/apache/spark/sql/execution/datasources/parquet/ParquetWriteSupport$$anonfun$org$apache$spark$sql$execution$datasources$parquet$ParquetWriteSupport$$makeWriter$3/3(org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport)
37	org/apache/spark/sql/catalyst/catalog/CatalogTable/withNewStorage$default$6()
38	org/apache/spark/sql/execution/datasources/parquet/ParquetWriteSupport$$anonfun$org$apache$spark$sql$execution$datasources$parquet$ParquetWriteSupport$$makeWriter$9/9(org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport)
39	org/apache/spark/sql/execution/datasources/parquet/ParquetWriteSupport$$anonfun$org$apache$spark$sql$execution$datasources$parquet$ParquetWriteSupport$$makeWriter$10/10(org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport)
40	scala/Predef$/genericWrapArray(java.lang.Object)
41	scala/Tuple2/_2$mcI$sp()
42	org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/copy$default$3()
43	scala/collection/mutable/StringBuilder/StringBuilder()
44	org/apache/spark/sql/execution/datasources/jdbc/JdbcUtils$/createTable(java.sql.Connection,org.apache.spark.sql.Dataset,org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions)
45	java/lang/String/trim()
46	scala/collection/Seq$/apply(scala.collection.Seq)
47	org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/copy$default$4()
48	org/apache/spark/sql/catalyst/expressions/codegen/ExprCode/code_$eq(java.lang.String)
49	org/apache/spark/sql/execution/datasources/parquet/ParquetWriteSupport$$anonfun$org$apache$spark$sql$execution$datasources$parquet$ParquetWriteSupport$$makeWriter$8/8(org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport)
50	org/apache/spark/sql/catalyst/parser/SqlBaseParser$ManageResourceContext/identifier()
51	scala/sys/package$/error(java.lang.String)
52	org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierContext/getText()
53	org/apache/spark/sql/execution/datasources/parquet/ParquetWriteSupport$$anonfun$org$apache$spark$sql$execution$datasources$parquet$ParquetWriteSupport$$makeWriter$2/2(org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport)
54	scala/Predef$/wrapRefArray(java.lang.Object[])
55	org/apache/spark/sql/catalyst/catalog/CatalogUtils$/stringToURI(java.lang.String)
56	org/apache/spark/sql/catalyst/catalog/SessionCatalog/alterTable(org.apache.spark.sql.catalyst.catalog.CatalogTable)
57	org/apache/spark/sql/execution/datasources/parquet/ParquetWriteSupport$$anonfun$1/1(org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport)
58	org/apache/spark/sql/execution/datasources/jdbc/JdbcUtils$/dropTable(java.sql.Connection,java.lang.String)
59	java/lang/String/toLowerCase(java.util.Locale)
60	org/apache/spark/sql/types/UserDefinedType/sqlType()
61	scala/collection/Seq$/canBuildFrom()
62	scala/StringContext/s(scala.collection.Seq)
63	scala/Option/isEmpty()
64	org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/copy$default$5()
65	org/apache/spark/sql/execution/datasources/parquet/ParquetWriteSupport$$anonfun$org$apache$spark$sql$execution$datasources$parquet$ParquetWriteSupport$$makeWriter$11/11(org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport)
66	org/apache/spark/sql/execution/command/DDLUtils$/verifyPartitionProviderIsHive(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.catalog.CatalogTable,java.lang.String)
67	org/apache/spark/sql/execution/command/DDLUtils$/verifyAlterTableType(org.apache.spark.sql.catalyst.catalog.SessionCatalog,org.apache.spark.sql.catalyst.catalog.CatalogTable,boolean)
68	org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/copy$default$6()
69	org/antlr/v4/runtime/Token/getType()
70	org/apache/spark/sql/execution/datasources/parquet/ParquetWriteSupport$$anonfun$org$apache$spark$sql$execution$datasources$parquet$ParquetWriteSupport$$makeWriter$7/7(org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport)
71	org/apache/spark/sql/execution/datasources/parquet/ParquetWriteSupport$$anonfun$org$apache$spark$sql$execution$datasources$parquet$ParquetWriteSupport$$makeWriter$1/1(org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport)
72	scala/collection/mutable/StringBuilder/append(java.lang.String)
73	org/apache/spark/sql/catalyst/catalog/CatalogTable/identifier()
74	java/lang/String/length()
75	org/apache/spark/sql/execution/command/ListJarsCommand$/apply$default$1()
76	scala/Tuple2/_1$mcI$sp()
77	java/lang/Object/equals(java.lang.Object)
78	org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/copy$default$1()
79	scala/collection/mutable/StringBuilder/append(java.lang.Object)
80	scala/Option/get()
81	org/apache/spark/sql/AnalysisException/AnalysisException(java.lang.String,scala.Option,scala.Option,scala.Option,scala.Option)
82	org/apache/spark/sql/catalyst/expressions/codegen/ExprCode/code()
83	org/apache/spark/sql/execution/datasources/parquet/ParquetWriteSupport$$anonfun$org$apache$spark$sql$execution$datasources$parquet$ParquetWriteSupport$$makeWriter$6/6(org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport)
84	org/apache/spark/sql/execution/datasources/jdbc/JdbcUtils$/createConnectionFactory(org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions)
85	org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$2()
86	scala/StringContext/StringContext(scala.collection.Seq)
87	org/apache/spark/sql/types/StructType/map(scala.Function1,scala.collection.generic.CanBuildFrom)
88	org/apache/spark/sql/execution/datasources/jdbc/JdbcUtils$/tableExists(java.sql.Connection,org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions)
89	scala/runtime/BoxesRunTime/boxToBoolean(boolean)
90	org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/copy(scala.collection.immutable.Map,org.apache.spark.sql.catalyst.catalog.CatalogStorageFormat,scala.collection.immutable.Map)
91	scala/Some/x()
92	scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)
93	org/apache/spark/sql/catalyst/parser/ParserUtils$/operationNotAllowed(java.lang.String,org.antlr.v4.runtime.ParserRuleContext)
94	org/apache/spark/sql/AnalysisException$/$lessinit$greater$default$3()
95	org/apache/spark/sql/execution/datasources/jdbc/JdbcUtils$/isCascadingTruncateTable(java.lang.String)
96	org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/copy$default$3()
97	scala/Tuple2/_1()
