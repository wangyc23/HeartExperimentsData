0	org/apache/spark/api/java/JavaPairRDD/saveAsNewAPIHadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.conf.Configuration)
1	org/apache/spark/api/java/AbstractJavaRDDLike/reduce(org.apache.spark.api.java.function.Function2)
2	code/spark/SparkSQL/main(java/lang/String[])/$anonymous3/()
3	org/apache/spark/sql/SQLContext/read()
4	org/apache/spark/sql/DataFrame/drop(org.apache.spark.sql.Column)
5	scala/Tuple2/_2()
6	org/apache/spark/sql/DataFrame/show(int)
7	org/apache/spark/SparkConf/setAppName(java.lang.String)
8	org/apache/spark/api/java/JavaPairRDD/join(org.apache.spark.api.java.JavaPairRDD)
9	org/apache/hadoop/mapreduce/Job/Job(org.apache.hadoop.conf.Configuration,java.lang.String)
10	org/apache/hadoop/fs/Path/Path(java.lang.String)
11	org/apache/spark/sql/DataFrameWriter/format(java.lang.String)
12	org/apache/spark/api/java/AbstractJavaRDDLike/collect()
13	org/apache/spark/api/java/JavaSparkContext/newAPIHadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.conf.Configuration)
14	org/apache/hadoop/util/ToolRunner/run(org.apache.hadoop.conf.Configuration,org.apache.hadoop.util.Tool,java.lang.String[])
15	code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous1/()
16	org/apache/spark/sql/SQLContext/createDataFrame(org.apache.spark.api.java.JavaRDD,org.apache.spark.sql.types.StructType)
17	org/apache/spark/sql/SQLContext/SQLContext(org.apache.spark.api.java.JavaSparkContext)
18	org/apache/spark/sql/DataFrame/select(java.lang.String,java.lang.String[])
19	org/apache/spark/sql/Column/$eq$eq$eq(java.lang.Object)
20	org/apache/spark/api/java/JavaSparkContext/stop()
21	org/apache/spark/sql/DataFrame/distinct()
22	org/apache/hadoop/mapreduce/Job/setOutputValueClass(java.lang.Class)
23	java/io/PrintWriter/close()
24	org/apache/spark/sql/types/StructType/StructType(org.apache.spark.sql.types.StructField[])
25	org/apache/spark/sql/DataFrame/coalesce(int)
26	a4example/BadRecordCount/main(java/lang/String[])/$anonymous1/()
27	org/apache/spark/api/java/AbstractJavaRDDLike/saveAsTextFile(java.lang.String)
28	org/apache/spark/api/java/JavaSparkContext/JavaSparkContext(org.apache.spark.SparkConf)
29	org/apache/spark/api/java/AbstractJavaRDDLike/count()
30	org/apache/hadoop/mapreduce/Job/setReducerClass(java.lang.Class)
31	code/spark/SparkSQL/main(java/lang/String[])/$anonymous5/()
32	code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous3/()
33	org/apache/spark/sql/DataFrame/filter(org.apache.spark.sql.Column)
34	org/apache/hadoop/conf/Configuration/Configuration()
35	java/io/PrintWriter/PrintWriter(java.io.Writer)
36	org/apache/spark/sql/DataFrameWriter/save(java.lang.String)
37	org/apache/spark/sql/DataFrame/count()
38	a4example/BadRecordCount/main(java/lang/String[])/$anonymous3/()
39	org/apache/spark/SparkConf/SparkConf()
40	org/apache/spark/sql/DataFrameReader/parquet(java.lang.String[])
41	org/apache/hadoop/mapreduce/Job/setOutputFormatClass(java.lang.Class)
42	org/apache/spark/api/java/JavaPairRDD/values()
43	wikibooks/hadoop/chapter07/MapSideJoin/MapSideJoin()
44	org/apache/spark/sql/DataFrame/drop(java.lang.String)
45	org/apache/spark/sql/DataFrame/javaRDD()
46	org/apache/hadoop/mapreduce/lib/output/FileOutputFormat/setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)
47	org/apache/hadoop/mapreduce/lib/input/FileInputFormat/addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)
48	org/apache/spark/api/java/AbstractJavaRDDLike/flatMap(org.apache.spark.api.java.function.FlatMapFunction)
49	code/spark/SparkSQL/main(java/lang/String[])/$anonymous2/()
50	java/io/PrintStream/println(java.lang.String)
51	code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous5/()
52	org/apache/spark/sql/DataFrameWriter/mode(org.apache.spark.sql.SaveMode)
53	java/lang/Throwable/getMessage()
54	org/apache/hadoop/mapreduce/Job/setMapperClass(java.lang.Class)
55	org/apache/spark/sql/DataFrameWriter/parquet(java.lang.String)
56	org/apache/spark/sql/types/DataTypes/createStructField(java.lang.String,org.apache.spark.sql.types.DataType,boolean)
57	org/apache/spark/api/java/JavaPairRDD/coalesce(int)
58	org/apache/spark/sql/DataFrame/write()
59	code/spark/SparkSQL/main(java/lang/String[])/$anonymous4/()
60	org/apache/spark/sql/DataFrame/join(org.apache.spark.sql.DataFrame,org.apache.spark.sql.Column)
61	org/apache/hadoop/mapreduce/Job/setInputFormatClass(java.lang.Class)
62	java/lang/System/exit(int)
63	org/apache/hadoop/mapreduce/Job/waitForCompletion(boolean)
64	org/apache/hadoop/mapreduce/Job/setOutputKeyClass(java.lang.Class)
65	java/io/PrintWriter/println(java.lang.String)
66	code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous2/()
67	org/apache/hadoop/mapreduce/Job/setJarByClass(java.lang.Class)
68	org/apache/spark/api/java/JavaPairRDD/reduceByKey(org.apache.spark.api.java.function.Function2)
69	org/apache/spark/sql/SQLContext/sql(java.lang.String)
70	a4example/BadRecordCount/main(java/lang/String[])/$anonymous2/()
71	org/apache/spark/sql/Column/equalTo(java.lang.Object)
72	org/apache/spark/api/java/JavaRDD/filter(org.apache.spark.api.java.function.Function)
73	org/apache/spark/SparkConf/setMaster(java.lang.String)
74	org/apache/spark/api/java/AbstractJavaRDDLike/map(org.apache.spark.api.java.function.Function)
75	code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous4/()
76	org/apache/spark/sql/DataFrame/registerTempTable(java.lang.String)
77	code/spark/SparkSQL/main(java/lang/String[])/$anonymous1/()
78	org/apache/spark/sql/DataFrame/printSchema()
79	a4example/BadRecordCount/main(java/lang/String[])/$anonymous4/()
80	java/io/FileWriter/FileWriter(java.lang.String)
81	org/apache/spark/sql/DataFrame/col(java.lang.String)
82	org/apache/spark/api/java/AbstractJavaRDDLike/mapToPair(org.apache.spark.api.java.function.PairFunction)
83	org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)
84	scala/Tuple2/_1()
85	org/apache/spark/sql/DataFrame/show()
