0	org/apache/spark/api/java/JavaPairRDD/saveAsNewAPIHadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.conf.Configuration)
1	org/apache/spark/api/java/AbstractJavaRDDLike/reduce(org.apache.spark.api.java.function.Function2)
2	code/spark/SparkSQL/main(java/lang/String[])/$anonymous3/()
3	org/apache/spark/sql/SQLContext/read()
4	org/apache/spark/sql/DataFrame/drop(org.apache.spark.sql.Column)
5	scala/Tuple2/_2()
6	org/apache/spark/sql/DataFrame/show(int)
7	org/apache/spark/SparkConf/setAppName(java.lang.String)
8	org/apache/spark/api/java/JavaPairRDD/join(org.apache.spark.api.java.JavaPairRDD)
9	org/apache/hadoop/mapreduce/Job/Job(org.apache.hadoop.conf.Configuration,java.lang.String)
10	org/apache/hadoop/fs/Path/Path(java.lang.String)
11	org/apache/spark/sql/DataFrameWriter/format(java.lang.String)
12	org/apache/spark/api/java/AbstractJavaRDDLike/collect()
13	org/apache/spark/api/java/JavaSparkContext/newAPIHadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.conf.Configuration)
14	org/apache/hadoop/util/ToolRunner/run(org.apache.hadoop.conf.Configuration,org.apache.hadoop.util.Tool,java.lang.String[])
15	code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous1/()
16	org/apache/spark/sql/SQLContext/createDataFrame(org.apache.spark.api.java.JavaRDD,org.apache.spark.sql.types.StructType)
17	org/apache/spark/sql/SQLContext/SQLContext(org.apache.spark.api.java.JavaSparkContext)
18	org/apache/spark/sql/DataFrame/select(java.lang.String,java.lang.String[])
19	org/apache/spark/sql/Column/$eq$eq$eq(java.lang.Object)
20	org/apache/spark/api/java/JavaSparkContext/stop()
21	org/apache/spark/sql/DataFrame/distinct()
22	org/apache/hadoop/mapreduce/Job/setOutputValueClass(java.lang.Class)
23	java/io/PrintWriter/close()
24	org/apache/spark/sql/types/StructType/StructType(org.apache.spark.sql.types.StructField[])
25	org/apache/spark/sql/DataFrame/coalesce(int)
26	a4example/BadRecordCount/main(java/lang/String[])/$anonymous1/()
27	org/apache/spark/api/java/AbstractJavaRDDLike/saveAsTextFile(java.lang.String)
28	org/apache/hadoop/conf/Configuration/setInt(java.lang.String,int)
29	org/apache/spark/api/java/JavaSparkContext/JavaSparkContext(org.apache.spark.SparkConf)
30	org/apache/spark/api/java/AbstractJavaRDDLike/count()
31	org/apache/hadoop/mapreduce/Job/setReducerClass(java.lang.Class)
32	code/spark/SparkSQL/main(java/lang/String[])/$anonymous5/()
33	code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous3/()
34	org/apache/spark/sql/DataFrame/filter(org.apache.spark.sql.Column)
35	org/apache/hadoop/conf/Configuration/Configuration()
36	java/io/PrintWriter/PrintWriter(java.io.Writer)
37	org/apache/spark/sql/DataFrameWriter/save(java.lang.String)
38	org/apache/spark/sql/DataFrame/count()
39	a4example/BadRecordCount/main(java/lang/String[])/$anonymous3/()
40	org/apache/spark/SparkConf/SparkConf()
41	org/apache/spark/sql/DataFrameReader/parquet(java.lang.String[])
42	org/apache/spark/api/java/JavaPairRDD/values()
43	org/apache/spark/sql/DataFrame/drop(java.lang.String)
44	org/apache/spark/sql/DataFrame/javaRDD()
45	org/apache/hadoop/mapreduce/lib/output/FileOutputFormat/setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)
46	org/apache/spark/api/java/AbstractJavaRDDLike/flatMap(org.apache.spark.api.java.function.FlatMapFunction)
47	code/spark/SparkSQL/main(java/lang/String[])/$anonymous2/()
48	java/io/PrintStream/println(java.lang.String)
49	code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous5/()
50	org/apache/spark/sql/DataFrameWriter/mode(org.apache.spark.sql.SaveMode)
51	java/lang/Throwable/getMessage()
52	org/apache/hadoop/mapreduce/Job/setMapperClass(java.lang.Class)
53	org/apache/spark/sql/DataFrameWriter/parquet(java.lang.String)
54	org/apache/spark/sql/types/DataTypes/createStructField(java.lang.String,org.apache.spark.sql.types.DataType,boolean)
55	org/apache/spark/api/java/JavaPairRDD/coalesce(int)
56	org/apache/spark/sql/DataFrame/write()
57	code/spark/SparkSQL/main(java/lang/String[])/$anonymous4/()
58	org/apache/spark/sql/DataFrame/join(org.apache.spark.sql.DataFrame,org.apache.spark.sql.Column)
59	java/lang/System/exit(int)
60	org/apache/hadoop/mapreduce/Job/waitForCompletion(boolean)
61	org/apache/hadoop/mapreduce/Job/setOutputKeyClass(java.lang.Class)
62	java/io/PrintWriter/println(java.lang.String)
63	code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous2/()
64	org/apache/hadoop/mapreduce/Job/setJarByClass(java.lang.Class)
65	org/apache/spark/api/java/JavaPairRDD/reduceByKey(org.apache.spark.api.java.function.Function2)
66	java/lang/Integer/parseInt(java.lang.String)
67	org/apache/spark/sql/SQLContext/sql(java.lang.String)
68	a4example/BadRecordCount/main(java/lang/String[])/$anonymous2/()
69	org/apache/spark/sql/Column/equalTo(java.lang.Object)
70	org/apache/spark/api/java/JavaRDD/filter(org.apache.spark.api.java.function.Function)
71	org/apache/spark/SparkConf/setMaster(java.lang.String)
72	org/apache/spark/api/java/AbstractJavaRDDLike/map(org.apache.spark.api.java.function.Function)
73	code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous4/()
74	org/apache/spark/sql/DataFrame/registerTempTable(java.lang.String)
75	code/spark/SparkSQL/main(java/lang/String[])/$anonymous1/()
76	org/apache/spark/sql/DataFrame/printSchema()
77	org/apache/hadoop/mapreduce/lib/input/FileInputFormat/setInputPaths(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path[])
78	a4example/BadRecordCount/main(java/lang/String[])/$anonymous4/()
79	java/io/FileWriter/FileWriter(java.lang.String)
80	org/apache/spark/sql/DataFrame/col(java.lang.String)
81	org/hf/mls/ar/hadoop/PreProcessJob/PreProcessJob()
82	org/apache/spark/api/java/AbstractJavaRDDLike/mapToPair(org.apache.spark.api.java.function.PairFunction)
83	org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)
84	scala/Tuple2/_1()
85	org/apache/spark/sql/DataFrame/show()
