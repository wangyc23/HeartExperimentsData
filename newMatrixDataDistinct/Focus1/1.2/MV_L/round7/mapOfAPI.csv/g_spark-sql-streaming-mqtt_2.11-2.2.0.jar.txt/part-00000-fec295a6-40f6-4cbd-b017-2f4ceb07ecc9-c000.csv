0	org/apache/spark/sql/execution/datasources/FileFormatWriter$$anonfun$write$1$$anonfun$apply$mcV$sp$1/1(org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1)
1	org/apache/spark/sql/DataFrameStatFunctions$$anonfun$sampleBy$1/1(org.apache.spark.sql.DataFrameStatFunctions)
2	scala/collection/immutable/Range$Inclusive/map(scala.Function1,scala.collection.generic.CanBuildFrom)
3	org/apache/spark/sql/types/StructType/fieldNames()
4	org/apache/spark/sql/catalyst/expressions/codegen/CodeFormatter$/stripOverlappingComments(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
5	org/apache/spark/sql/catalyst/expressions/codegen/CodeAndComment/CodeAndComment(java.lang.String,scala.collection.Map)
6	scala/collection/TraversableOnce/mkString(java.lang.String)
7	scala/MatchError/MatchError(java.lang.Object)
8	org/apache/spark/sql/DataFrameStatFunctions$$anonfun$sampleBy$2/2(org.apache.spark.sql.DataFrameStatFunctions,scala.collection.immutable.Map)
9	scala/reflect/api/TypeTags$TypeTag$/Double()
10	scala/Predef$/$conforms()
11	org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/declareAddedFunctions()
12	org/apache/spark/rdd/RDD/partitions()
13	scala/Tuple2/_2()
14	org/apache/spark/sql/execution/datasources/FileFormatWriter$$anonfun$write$1$$anonfun$apply$mcV$sp$3/3(org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1)
15	org/apache/spark/sql/execution/datasources/FileFormatWriter$/logInfo(scala.Function0)
16	org/apache/spark/sql/execution/columnar/GenerateColumnAccessor$$anonfun$1/1(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
17	scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)
18	org/apache/spark/sql/execution/columnar/GenerateColumnAccessor$$anonfun$2/2(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext,scala.runtime.IntRef)
19	scala/collection/mutable/ListBuffer/slice(int,int)
20	scala/reflect/runtime/package$/universe()
21	org/apache/spark/sql/execution/columnar/GenerateColumnAccessor$$anonfun$5/5()
22	org/apache/spark/sql/execution/SortExec/execute()
23	scala/collection/mutable/ArrayOps/take(int)
24	org/apache/spark/internal/io/FileCommitProtocol/abortJob(org.apache.hadoop.mapreduce.JobContext)
25	org/apache/spark/internal/io/FileCommitProtocol/commitJob(org.apache.hadoop.mapreduce.JobContext,scala.collection.Seq)
26	scala/collection/Seq/foreach(scala.Function1)
27	scala/collection/Seq/size()
28	scala/runtime/RichInt$/until$extension0(int,int)
29	org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/getPlaceHolderToComments()
30	org/apache/spark/sql/execution/streaming/TextSocketSource$$anonfun$3/3(org.apache.spark.sql.execution.streaming.TextSocketSource)
31	org/apache/spark/sql/SQLContext$implicits$/newProductEncoder(scala.reflect.api.TypeTags$TypeTag)
32	org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)
33	scala/collection/generic/GenericTraversableTemplate/unzip(scala.Function1)
34	scala/reflect/ClassTag$/apply(java.lang.Class)
35	scala/collection/Iterable/forall(scala.Function1)
36	scala/collection/mutable/StringBuilder/toString()
37	scala/reflect/api/TypeTags$TypeTag$/Any()
38	scala/Array$/empty(scala.reflect.ClassTag)
39	scala/collection/mutable/ArrayOps/toSeq()
40	scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)
41	scala/Predef$/intWrapper(int)
42	org/apache/spark/sql/execution/datasources/FileFormatWriter$$anonfun$write$1$$anonfun$apply$mcV$sp$2/2(org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1,org.apache.spark.sql.execution.datasources.FileFormatWriter$WriteTaskResult[])
43	org/apache/spark/sql/execution/columnar/GenerateColumnAccessor$/newCodeGenContext()
44	scala/Option/getOrElse(scala.Function0)
45	org/apache/spark/sql/Column$/apply(java.lang.String)
46	scala/Predef$/genericWrapArray(java.lang.Object)
47	scala/Function1/apply(java.lang.Object)
48	org/apache/spark/internal/io/FileCommitProtocol/setupJob(org.apache.hadoop.mapreduce.JobContext)
49	org/apache/spark/sql/execution/columnar/GenerateColumnAccessor$$anonfun$3/3(org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext)
50	scala/collection/Iterator/zipWithIndex()
51	org/apache/spark/sql/functions$/udf(scala.Function2,scala.reflect.api.TypeTags$TypeTag,scala.reflect.api.TypeTags$TypeTag,scala.reflect.api.TypeTags$TypeTag)
52	scala/reflect/ClassTag$/Any()
53	org/apache/spark/sql/Dataset$$anonfun$7/7(org.apache.spark.sql.Dataset,int,scala.runtime.ObjectRef,scala.runtime.VolatileByteRef)
54	scala/collection/mutable/StringBuilder/StringBuilder()
55	org/apache/spark/sql/execution/streaming/TextSocketSource$$anonfun$2/2(org.apache.spark.sql.execution.streaming.TextSocketSource)
56	scala/collection/TraversableOnce/addString(scala.collection.mutable.StringBuilder,java.lang.String,java.lang.String,java.lang.String)
57	org/apache/spark/sql/execution/columnar/GenerateColumnAccessor$/logDebug(scala.Function0)
58	scala/reflect/api/TypeTags/TypeTag()
59	scala/Predef$/require(boolean,scala.Function0)
60	scala/Predef$/wrapRefArray(java.lang.Object[])
61	scala/Predef$/intArrayOps(int[])
62	scala/runtime/BoxesRunTime/boxToInteger(int)
63	scala/collection/mutable/ArrayOps/distinct()
64	org/apache/spark/sql/execution/columnar/GenerateColumnAccessor$$anonfun$create$1/1(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
65	org/apache/spark/sql/execution/datasources/FileFormatWriter$/logError(scala.Function0,java.lang.Throwable)
66	scala/runtime/RichInt$/to$extension0(int,int)
67	scala/collection/Seq$/canBuildFrom()
68	scala/Predef$DummyImplicit$/dummyImplicit()
69	scala/StringContext/s(scala.collection.Seq)
70	java/lang/Class/getName()
71	org/apache/spark/sql/functions$/rand(long)
72	scala/collection/immutable/Map/values()
73	scala/collection/Seq/length()
74	org/apache/spark/sql/execution/datasources/FileFormatWriter$$anonfun$write$1$$anonfun$13/13(org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1)
75	scala/Array$/fallbackCanBuildFrom(scala.Predef$DummyImplicit)
76	org/apache/spark/sql/execution/datasources/FileFormatWriter$$anonfun$write$1$$anonfun$15/15(org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1)
77	scala/collection/mutable/ArrayOps/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)
78	org/apache/spark/sql/Dataset$$anonfun$showString$2/2(org.apache.spark.sql.Dataset,int,int[])
79	scala/Array$/fill(int,scala.Function0,scala.reflect.ClassTag)
80	scala/collection/Iterator/foreach(scala.Function1)
81	scala/collection/Seq/mkString(java.lang.String)
82	scala/reflect/api/JavaUniverse/runtimeMirror(java.lang.ClassLoader)
83	org/apache/spark/sql/Dataset$$anonfun$showString$1/1(org.apache.spark.sql.Dataset,int[])
84	scala/collection/Seq/grouped(int)
85	scala/runtime/ObjectRef/zero()
86	scala/reflect/ClassTag$/Int()
87	scala/reflect/api/TypeTags$TypeTag$/apply(scala.reflect.api.Mirror,scala.reflect.api.TypeCreator)
88	scala/collection/mutable/StringBuilder/append(java.lang.String)
89	scala/collection/Seq/head()
90	scala/Array$/canBuildFrom(scala.reflect.ClassTag)
91	scala/runtime/VolatileByteRef/create(byte)
92	org/apache/spark/sql/execution/streaming/LongOffset$/convert(org.apache.spark.sql.execution.streaming.Offset)
93	org/apache/spark/sql/Dataset$$anonfun$showString$3/3(org.apache.spark.sql.Dataset,int,scala.collection.mutable.StringBuilder,int[])
94	scala/collection/IterableLike/zipWithIndex(scala.collection.generic.CanBuildFrom)
95	org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function2,scala.collection.Seq,scala.Function2,scala.reflect.ClassTag)
96	scala/collection/Seq/tail()
97	java/lang/Class/getClassLoader()
98	scala/collection/mutable/ArrayOps/addString(scala.collection.mutable.StringBuilder,java.lang.String,java.lang.String,java.lang.String)
99	org/apache/spark/sql/DataFrameStatFunctions$$anonfun$1/1(org.apache.spark.sql.DataFrameStatFunctions,scala.collection.immutable.Map)
100	org/apache/spark/sql/catalyst/expressions/codegen/CodegenContext/declareMutableStates()
101	org/apache/spark/sql/execution/streaming/TextSocketSource$$anonfun$4/4(org.apache.spark.sql.execution.streaming.TextSocketSource)
102	scala/Option/flatMap(scala.Function1)
103	org/apache/spark/sql/catalyst/expressions/codegen/GeneratedClass/generate(java.lang.Object[])
104	scala/runtime/RichInt$/max$extension(int,int)
105	scala/Predef$/refArrayOps(java.lang.Object[])
106	scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)
107	scala/StringContext/StringContext(scala.collection.Seq)
108	org/apache/spark/sql/execution/datasources/FileFormatWriter$$anonfun$write$1$$anonfun$apply$mcV$sp$4/4(org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1)
109	org/apache/spark/sql/execution/streaming/TextSocketSource$$typecreator2$1/1(org.apache.spark.sql.execution.streaming.TextSocketSource)
110	org/apache/spark/sql/execution/SortExec$/apply$default$4()
111	scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)
112	org/apache/bahir/sql/streaming/mqtt/MQTTTextStreamSource$$typecreator3$1/1(org.apache.bahir.sql.streaming.mqtt.MQTTTextStreamSource)
113	org/apache/spark/sql/Dataset$$anonfun$1/1(org.apache.spark.sql.Dataset)
114	org/apache/spark/sql/Dataset$$anonfun$9/9(org.apache.spark.sql.Dataset)
115	org/apache/spark/sql/execution/columnar/GenerateColumnAccessor$$anonfun$4/4()
116	org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/compile(org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment)
117	scala/collection/mutable/ArrayOps/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)
118	scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)
119	scala/collection/immutable/IndexedSeq$/canBuildFrom()
120	scala/runtime/IntRef/create(int)
121	scala/reflect/api/TypeTags$TypeTag$/Boolean()
122	org/apache/spark/sql/execution/datasources/FileFormatWriter$$anonfun$write$1$$anonfun$12/12(org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1)
123	org/apache/spark/sql/execution/datasources/FileFormatWriter$$anonfun$write$1$$anonfun$14/14(org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1)
124	scala/Tuple2/_1()
